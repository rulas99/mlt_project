{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c695be96-a776-454b-bc3b-54358026ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from onnx_converter.converter import sentence_transformers_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65960833-fb45-4127-9754-59b711896e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = SentenceTransformer.load('./results/domain_adaptation_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68730452-7c8e-47a8-adb6-04db8ec722aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estudiante/mlt_project/onnx_converter/converter.py:92: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  \"token_embeddings\": torch.Tensor(hidden_state[0]),\n",
      "/home/estudiante/mlt_project/onnx_converter/converter.py:93: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  \"attention_mask\": torch.Tensor(attention_mask),\n",
      "/home/estudiante/mlt_project/onnx_converter/converter.py:103: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sentence_embedding.shape[0] == 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformerModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooling): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (adapter): AdapterModule(\n",
       "    (dense1): Linear(in_features=384, out_features=1024, bias=True)\n",
       "    (dense2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (output): Linear(in_features=512, out_features=384, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (normalization): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the model to use onnx format\n",
    "onnx_model = sentence_transformers_onnx(\n",
    "    model,\n",
    "    output_path=\"triton/model_repository/domain_adapter/1/model\",\n",
    "    config_path=\"results/domain_adaptation_model\",\n",
    "    device=torch.device(\"cpu\")\n",
    ")\n",
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426b0c86-fe13-42b7-8abd-95f963f39567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13528061"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute embeddings for two textual contents and compute dot product\n",
    "with torch.no_grad():\n",
    "    tokens_1 = model.tokenize([\"Composable Lightweight Processors\"])\n",
    "    embedding_1 = onnx_model(tokens_1[\"input_ids\"], tokens_1[\"attention_mask\"], tokens_1[\"token_type_ids\"]).detach().numpy()\n",
    "    \n",
    "    tokens_2 = model.tokenize([\"ocean\"])\n",
    "    embedding_2 = onnx_model(tokens_2[\"input_ids\"], tokens_2[\"attention_mask\"], tokens_2[\"token_type_ids\"]).detach().numpy()\n",
    "\n",
    "# Same results as Pytorch-based model - so conversion seems accurate\n",
    "np.dot(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0722b13c-cf77-45b6-947c-32c1d36ace91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import triton_to_np_dtype\n",
    "\n",
    "# tokenize sentence\n",
    "sentence=[\"Composable Lightweight Processors\"]\n",
    "inputs = model.tokenize(sentence)\n",
    "\n",
    "input_ids = inputs['input_ids'].numpy()\n",
    "token_type_ids = inputs['token_type_ids'].numpy()\n",
    "attention_mask = inputs['attention_mask'].numpy()\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08062cf-f20c-4ca6-8369-3e1551ab6bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tritonclient.http._infer_result.InferResult at 0x73496ba481c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up client\n",
    "client = httpclient.InferenceServerClient(url=\"localhost:8000\")\n",
    "\n",
    "input_ids_triton = httpclient.InferInput(\"input_ids\", input_ids.shape, datatype=\"INT64\")\n",
    "input_ids_triton.set_data_from_numpy(input_ids.astype(np.int64))\n",
    "\n",
    "token_type_ids_triton = httpclient.InferInput(\"token_type_ids\", token_type_ids.shape, datatype=\"INT64\")\n",
    "token_type_ids_triton.set_data_from_numpy(token_type_ids.astype(np.int64))\n",
    "\n",
    "attention_mask_triton = httpclient.InferInput(\"attention_mask\", attention_mask.shape, datatype=\"INT64\")\n",
    "attention_mask_triton.set_data_from_numpy(attention_mask.astype(np.int64))\n",
    "\n",
    "output = httpclient.InferRequestedOutput(\"1770\")\n",
    "\n",
    "# Querying the server\n",
    "results = client.infer(model_name=\"domain_adapter\", inputs=[input_ids_triton, token_type_ids_triton, attention_mask_triton], outputs=[output])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce55c8c-a026-4117-ac6a-6f07abd5860e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0256958 ,  0.01481628,  0.07751465,  0.01100922, -0.08972168,\n",
       "       -0.03074646, -0.09466553, -0.03234863,  0.00525665, -0.01855469,\n",
       "        0.01269531, -0.04891968, -0.02073669,  0.00374222,  0.09515381,\n",
       "       -0.15673828,  0.01867676,  0.04284668,  0.08343506,  0.07293701,\n",
       "       -0.05923462, -0.07788086, -0.04202271,  0.0297699 ,  0.05596924,\n",
       "        0.03842163,  0.01280975, -0.07324219,  0.10656738,  0.03051758,\n",
       "        0.00310135, -0.04406738, -0.0335083 , -0.01245117,  0.03692627,\n",
       "        0.03503418, -0.01293945, -0.03292847, -0.04998779, -0.10693359,\n",
       "        0.01838684,  0.00383759,  0.03805542,  0.05883789,  0.06506348,\n",
       "        0.04418945,  0.05438232,  0.02909851, -0.04785156, -0.03979492,\n",
       "        0.00611115,  0.07922363,  0.09942627, -0.01474762, -0.00510788,\n",
       "       -0.0413208 ,  0.08270264, -0.01644897,  0.000669  , -0.0647583 ,\n",
       "        0.10211182, -0.06185913, -0.0216217 , -0.01271057, -0.01105499,\n",
       "       -0.05075073,  0.04049683, -0.01849365, -0.03598022,  0.02243042,\n",
       "       -0.00230598, -0.01478577,  0.02519226, -0.01831055, -0.09674072,\n",
       "       -0.0227356 , -0.01725769, -0.10736084,  0.00763702, -0.01236725,\n",
       "        0.01823425, -0.05151367, -0.03518677, -0.05181885, -0.03120422,\n",
       "        0.04678345,  0.05038452,  0.03717041,  0.04989624, -0.04721069,\n",
       "        0.01352692, -0.01966858, -0.05560303,  0.04684448,  0.00837708,\n",
       "       -0.06201172, -0.03515625,  0.05673218, -0.08453369, -0.13696289,\n",
       "        0.07189941, -0.0670166 ,  0.04644775,  0.03903198, -0.09893799,\n",
       "        0.0196991 , -0.02716064, -0.01493073, -0.04244995, -0.01205444,\n",
       "        0.03253174,  0.10913086, -0.03546143,  0.07501221,  0.01108551,\n",
       "        0.02627563, -0.05935669, -0.07843018, -0.00356102,  0.07019043,\n",
       "        0.03314209, -0.05282593, -0.01257324,  0.01428223,  0.03323364,\n",
       "        0.08630371, -0.05645752, -0.07287598,  0.02435303,  0.05319214,\n",
       "       -0.01301575, -0.06137085, -0.05679321, -0.04171753,  0.03096008,\n",
       "        0.08587646, -0.01203156,  0.01065063,  0.0135498 , -0.04620361,\n",
       "       -0.02697754,  0.02682495, -0.01290131, -0.07037354,  0.07092285,\n",
       "        0.08416748, -0.00494385, -0.0075798 , -0.06072998, -0.07269287,\n",
       "       -0.09521484,  0.07727051, -0.01982117,  0.01067352, -0.01480865,\n",
       "        0.00904083, -0.08190918, -0.00478745, -0.06228638, -0.07781982,\n",
       "        0.0513916 ,  0.0993042 ,  0.04733276,  0.01483917, -0.03890991,\n",
       "        0.01114655, -0.02436829, -0.03092957,  0.03167725,  0.04190063,\n",
       "       -0.02934265,  0.02450562, -0.03192139, -0.01930237, -0.00134563,\n",
       "        0.03240967,  0.08898926, -0.08233643, -0.03378296,  0.03372192,\n",
       "       -0.00923157, -0.0657959 ,  0.07855225,  0.06335449,  0.11218262,\n",
       "        0.00245476, -0.04321289,  0.04373169, -0.03860474, -0.02362061,\n",
       "       -0.11230469,  0.01905823,  0.01852417,  0.04571533,  0.06695557,\n",
       "        0.0137558 ,  0.00116348, -0.02825928,  0.00606537,  0.01776123,\n",
       "        0.06945801, -0.0168457 , -0.03060913, -0.05343628, -0.02104187,\n",
       "       -0.0027256 , -0.11322021, -0.01454926,  0.06018066,  0.04562378,\n",
       "       -0.00983429,  0.02012634,  0.05343628, -0.04095459, -0.03814697,\n",
       "        0.0307312 ,  0.01077271,  0.02920532, -0.00439835, -0.06567383,\n",
       "       -0.00891113,  0.05682373,  0.02267456, -0.04492188,  0.03491211,\n",
       "       -0.10894775, -0.10400391,  0.04846191, -0.05438232,  0.02706909,\n",
       "       -0.02423096, -0.06549072, -0.09197998,  0.00226212,  0.03820801,\n",
       "        0.08508301,  0.02328491,  0.02897644, -0.04394531, -0.06433105,\n",
       "       -0.02496338,  0.03323364, -0.04370117,  0.03570557,  0.02165222,\n",
       "       -0.02116394,  0.09741211,  0.01402283,  0.00379562,  0.02655029,\n",
       "       -0.08648682,  0.04428101, -0.01776123, -0.07922363, -0.04473877,\n",
       "       -0.01557159,  0.01457977,  0.04678345, -0.03059387, -0.06155396,\n",
       "       -0.0519104 ,  0.03952026,  0.00764847,  0.09814453,  0.0586853 ,\n",
       "        0.0769043 , -0.02055359,  0.01596069, -0.05847168,  0.02192688,\n",
       "        0.02641296, -0.05819702,  0.04776001,  0.00036836, -0.03326416,\n",
       "       -0.05224609, -0.00415421,  0.03201294, -0.04232788, -0.10211182,\n",
       "        0.03305054,  0.01902771,  0.03050232, -0.04815674, -0.00981903,\n",
       "        0.02886963,  0.02030945,  0.03775024, -0.00990295,  0.04058838,\n",
       "        0.04980469,  0.02772522,  0.05383301, -0.02687073, -0.0559082 ,\n",
       "        0.0010128 ,  0.00313187, -0.04110718,  0.05596924,  0.00540543,\n",
       "        0.03579712,  0.05838013, -0.04421997, -0.00043869, -0.0243988 ,\n",
       "        0.00100708,  0.03656006, -0.02653503, -0.05245972, -0.03433228,\n",
       "       -0.11566162,  0.00839233,  0.02009583,  0.03994751,  0.06140137,\n",
       "       -0.02580261,  0.08233643, -0.05050659, -0.00517654, -0.05438232,\n",
       "        0.03878784,  0.08398438, -0.06872559,  0.04760742,  0.00324249,\n",
       "       -0.08807373, -0.03216553, -0.08496094, -0.01027679,  0.00775528,\n",
       "        0.00116348, -0.01860046,  0.07208252, -0.05270386, -0.06854248,\n",
       "        0.05105591, -0.06280518,  0.03341675, -0.1104126 ,  0.00769806,\n",
       "        0.00698471, -0.04263306, -0.01068878,  0.0802002 , -0.06005859,\n",
       "        0.00042868,  0.0168457 ,  0.05996704,  0.03668213,  0.02108765,\n",
       "       -0.01696777, -0.05175781,  0.0329895 ,  0.01870728, -0.01856995,\n",
       "       -0.04153442, -0.02095032,  0.14807129,  0.02822876, -0.01208496,\n",
       "        0.00843811,  0.0189209 , -0.04946899, -0.00485229,  0.08898926,\n",
       "       -0.07556152, -0.07427979,  0.02696228, -0.02232361,  0.08435059,\n",
       "        0.0280304 ,  0.15563965, -0.00383568,  0.01649475,  0.00645828,\n",
       "       -0.00078869, -0.03900146,  0.04296875, -0.00959015, -0.02281189,\n",
       "        0.06628418, -0.06573486,  0.05935669,  0.0087204 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_output = results.as_numpy('1770')\n",
    "inference_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
