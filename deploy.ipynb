{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c695be96-a776-454b-bc3b-54358026ad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estudiante/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from converter.converter import sentence_transformers_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65960833-fb45-4127-9754-59b711896e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = SentenceTransformer.load('./results/domain_adaptation_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68730452-7c8e-47a8-adb6-04db8ec722aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estudiante/mlt_project/converter/converter.py:92: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  \"token_embeddings\": torch.Tensor(hidden_state[0]),\n",
      "/home/estudiante/mlt_project/converter/converter.py:93: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  \"attention_mask\": torch.Tensor(attention_mask),\n",
      "/home/estudiante/mlt_project/converter/converter.py:103: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sentence_embedding.shape[0] == 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformerModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooling): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (adapter): AdapterModule(\n",
       "    (dense1): Linear(in_features=384, out_features=1024, bias=True)\n",
       "    (dense2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (output): Linear(in_features=512, out_features=384, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (normalization): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the model to use onnx format\n",
    "onnx_model = sentence_transformers_onnx(\n",
    "    model,\n",
    "    output_path=\"triton/model_repository/domain_adapter/1/model\",\n",
    "    config_path=\"results/domain_adaptation_model\",\n",
    "    device=torch.device(\"cpu\")\n",
    ")\n",
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426b0c86-fe13-42b7-8abd-95f963f39567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13528061"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute embeddings for two textual contents and compute dot product\n",
    "with torch.no_grad():\n",
    "    tokens_1 = model.tokenize([\"Composable Lightweight Processors\"])\n",
    "    embedding_1 = onnx_model(tokens_1[\"input_ids\"], tokens_1[\"attention_mask\"], tokens_1[\"token_type_ids\"]).detach().numpy()\n",
    "    \n",
    "    tokens_2 = model.tokenize([\"ocean\"])\n",
    "    embedding_2 = onnx_model(tokens_2[\"input_ids\"], tokens_2[\"attention_mask\"], tokens_2[\"token_type_ids\"]).detach().numpy()\n",
    "\n",
    "# Same results as Pytorch-based model - so conversion seems accurate\n",
    "np.dot(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0722b13c-cf77-45b6-947c-32c1d36ace91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  4012,  6873, 19150, 12038, 18017,   102]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import triton_to_np_dtype\n",
    "\n",
    "# tokenize sentence\n",
    "sentence=[\"Composable Lightweight Processors\"]\n",
    "inputs = model.tokenize(sentence)\n",
    "\n",
    "input_ids = inputs['input_ids'].numpy()\n",
    "token_type_ids = inputs['token_type_ids'].numpy()\n",
    "attention_mask = inputs['attention_mask'].numpy()\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b1cbee-fc65-4e79-962b-420964a0b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"input_ids\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 7\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"batch_size\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_param: \"max_seq_len\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"attention_mask\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 7\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"batch_size\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_param: \"max_seq_len\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"token_type_ids\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 7\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"batch_size\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_param: \"max_seq_len\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"1770\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"Gather1770_dim_0\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "model = onnx.load(r\"triton/model_repository/domain_adapter/1/model.onnx\")\n",
    "\n",
    "# model is an onnx model\n",
    "graph = model.graph\n",
    "# graph inputs\n",
    "for input_name in graph.input:\n",
    "    print(input_name)\n",
    "# graph outputs\n",
    "for output_name in graph.output:\n",
    "    print(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08062cf-f20c-4ca6-8369-3e1551ab6bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tritonclient.http._infer_result.InferResult at 0x72add6f85420>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up client\n",
    "client = httpclient.InferenceServerClient(url=\"localhost:8000\")\n",
    "\n",
    "input_ids_triton = httpclient.InferInput(\"input_ids\", input_ids.shape, datatype=\"INT64\")\n",
    "input_ids_triton.set_data_from_numpy(input_ids.astype(np.int64))\n",
    "\n",
    "token_type_ids_triton = httpclient.InferInput(\"token_type_ids\", token_type_ids.shape, datatype=\"INT64\")\n",
    "token_type_ids_triton.set_data_from_numpy(token_type_ids.astype(np.int64))\n",
    "\n",
    "attention_mask_triton = httpclient.InferInput(\"attention_mask\", attention_mask.shape, datatype=\"INT64\")\n",
    "attention_mask_triton.set_data_from_numpy(attention_mask.astype(np.int64))\n",
    "\n",
    "output = httpclient.InferRequestedOutput(\"1770\")\n",
    "\n",
    "# Querying the server\n",
    "results = client.infer(model_name=\"domain_adapter\", inputs=[input_ids_triton, token_type_ids_triton, attention_mask_triton], outputs=[output])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce55c8c-a026-4117-ac6a-6f07abd5860e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.52750462e-02,  2.90051084e-02,  8.03524330e-02,  2.03186739e-02,\n",
       "       -8.10070485e-02, -4.72998135e-02, -1.10489026e-01, -4.12289761e-02,\n",
       "       -1.34759089e-02, -4.28274386e-02,  9.59829148e-03, -4.44858335e-02,\n",
       "       -1.08630229e-02, -2.58579087e-02,  6.40803948e-02, -1.47565454e-01,\n",
       "        4.42228206e-02,  4.39664647e-02,  6.85295537e-02,  5.24679013e-02,\n",
       "       -3.27280760e-02, -8.71130005e-02, -3.72967981e-02,  3.93275321e-02,\n",
       "        3.54713574e-02,  3.22213285e-02,  2.48689000e-02, -4.15771417e-02,\n",
       "        1.17586717e-01,  2.10608263e-02, -1.59455277e-02, -3.34884822e-02,\n",
       "       -4.31342572e-02, -1.00450004e-02,  5.43379895e-02,  2.15828903e-02,\n",
       "        3.05772736e-03, -2.57921182e-02, -4.77049947e-02, -1.08501181e-01,\n",
       "        1.15717724e-02,  3.36790979e-02,  2.48274282e-02,  6.98414892e-02,\n",
       "        5.24340160e-02,  6.22562170e-02,  4.54524904e-02,  2.85202339e-02,\n",
       "       -4.66927923e-02, -3.11973747e-02,  1.38132018e-03,  9.28488374e-02,\n",
       "        5.40151000e-02, -4.02022451e-02, -2.09376365e-02, -6.04497343e-02,\n",
       "        8.77030417e-02, -2.42756754e-02, -1.71447564e-02, -5.05327210e-02,\n",
       "        1.09825619e-01, -1.02858819e-01, -2.78681237e-02, -4.55302699e-03,\n",
       "        1.49343871e-02, -4.91585881e-02,  5.67555949e-02,  7.14505836e-03,\n",
       "       -3.19549143e-02,  1.66825652e-02, -1.77455917e-02,  1.01310313e-02,\n",
       "       -6.75629417e-05, -2.57895533e-02, -8.78713280e-02, -1.01540526e-02,\n",
       "       -1.29980762e-02, -8.47719908e-02,  1.01747308e-02, -5.04622562e-03,\n",
       "        1.95413511e-02, -8.01220611e-02, -4.98702116e-02, -6.87429607e-02,\n",
       "       -4.35104445e-02,  6.50346875e-02,  4.03289795e-02,  5.71616739e-02,\n",
       "        5.46707436e-02, -6.74206018e-02, -5.24611957e-03, -7.23020872e-03,\n",
       "       -4.99799363e-02,  3.89193185e-02,  6.38734084e-03, -6.39764145e-02,\n",
       "       -1.95436124e-02,  4.23090123e-02, -9.52234715e-02, -1.09211437e-01,\n",
       "        6.36993945e-02, -5.58689870e-02,  2.04371512e-02,  3.21227945e-02,\n",
       "       -8.64227936e-02,  1.62872877e-02, -3.66916880e-02, -2.10494939e-02,\n",
       "       -1.59030613e-02, -1.19449235e-02,  3.80447246e-02,  1.15626723e-01,\n",
       "       -3.23237628e-02,  7.78963938e-02, -8.79839901e-03,  2.96639577e-02,\n",
       "       -4.03987765e-02, -5.65932132e-02,  1.02992710e-02,  7.98882097e-02,\n",
       "        2.56123655e-02, -5.66610806e-02, -6.77657872e-03,  2.56427797e-04,\n",
       "        5.40655218e-02,  1.10143542e-01, -5.51621728e-02, -5.93618192e-02,\n",
       "        1.01930453e-02,  3.39231342e-02, -1.67837311e-02, -6.72043413e-02,\n",
       "       -1.89948119e-02, -6.99518546e-02,  3.02193351e-02,  6.10873587e-02,\n",
       "       -1.00538339e-02,  6.96385326e-03,  1.56900790e-02, -3.51189375e-02,\n",
       "        1.50351971e-02,  1.85944531e-02, -3.65810804e-02, -5.56634441e-02,\n",
       "        7.39764720e-02,  8.83740410e-02,  9.93239321e-03, -1.97491944e-02,\n",
       "       -5.79930469e-02, -6.03705756e-02, -9.03732628e-02,  7.52602816e-02,\n",
       "       -1.60765052e-02,  3.22295260e-03, -8.36126681e-04,  1.82498861e-02,\n",
       "       -9.19697434e-02,  2.29959544e-02, -5.31925894e-02, -8.05250555e-02,\n",
       "        3.95260341e-02,  8.97341445e-02,  5.06662391e-02,  1.44275390e-02,\n",
       "       -4.65116911e-02,  6.31154375e-03, -2.37449631e-02, -1.74254067e-02,\n",
       "        3.57353501e-02,  2.88994052e-02, -1.93506498e-02,  6.51245192e-03,\n",
       "        1.72644388e-03, -8.41842312e-03,  2.73673963e-02,  4.62898500e-02,\n",
       "        6.70196041e-02, -9.54080299e-02, -2.60922965e-02,  1.03466893e-02,\n",
       "       -2.31511164e-02, -8.85392204e-02,  9.92010459e-02,  4.61701192e-02,\n",
       "        1.15217932e-01,  2.24692207e-02,  7.08696852e-03,  3.49926054e-02,\n",
       "       -2.26205140e-02, -2.96441521e-02, -1.47402719e-01,  3.91404666e-02,\n",
       "        2.02932842e-02,  2.59305928e-02,  5.68365008e-02,  4.76114312e-03,\n",
       "        2.41467101e-03, -2.33540386e-02,  2.19785888e-02,  7.09003676e-03,\n",
       "        9.12473053e-02, -4.30701450e-02, -3.97123694e-02, -4.43390459e-02,\n",
       "       -3.56421922e-03, -2.80488026e-03, -9.69214365e-02, -1.21228239e-02,\n",
       "        8.55085403e-02,  3.29028182e-02,  1.39278192e-02,  4.22928073e-02,\n",
       "        2.94717532e-02, -4.94368784e-02, -6.19177446e-02,  2.20863000e-02,\n",
       "        2.69208681e-02,  6.58175349e-02, -7.42317270e-03, -5.27803563e-02,\n",
       "        4.17752378e-03,  5.39083257e-02,  3.38325538e-02, -3.47053111e-02,\n",
       "        1.99302249e-02, -1.23451352e-01, -1.01938203e-01,  3.97692136e-02,\n",
       "       -5.49605675e-02,  5.46327755e-02, -2.88124923e-02, -7.94948414e-02,\n",
       "       -7.94829354e-02,  8.99982289e-04,  3.74799632e-02,  6.11337461e-02,\n",
       "        3.01857423e-02,  3.69866341e-02, -5.31512350e-02, -5.80689013e-02,\n",
       "       -4.12823148e-02,  1.59845017e-02, -4.09977287e-02,  5.80408797e-02,\n",
       "        1.43582746e-02, -2.30319444e-02,  9.63686258e-02,  3.02916467e-02,\n",
       "        8.66015814e-03,  2.32191198e-02, -1.02228358e-01,  3.37636881e-02,\n",
       "       -1.19512258e-02, -6.42529428e-02, -2.17620563e-02, -1.38761764e-02,\n",
       "        1.80776939e-02,  2.07183100e-02, -1.94475520e-02, -6.77082986e-02,\n",
       "       -4.36979495e-02,  4.88246493e-02,  2.85786670e-02,  6.02254011e-02,\n",
       "        6.83572814e-02,  8.33903402e-02, -3.87418382e-02, -9.30265896e-03,\n",
       "       -4.13959324e-02,  2.55950205e-02,  3.53316590e-02, -7.18959123e-02,\n",
       "        5.63280471e-02, -2.34062900e-03,  3.77631979e-03, -6.67560026e-02,\n",
       "       -1.37762120e-03,  2.44875420e-02, -5.38510196e-02, -8.50402489e-02,\n",
       "        5.78743964e-02,  3.63812670e-02,  4.70335335e-02, -4.49203774e-02,\n",
       "       -2.85828058e-02,  1.86716225e-02,  2.27039699e-02,  4.67703603e-02,\n",
       "       -1.23602198e-02,  3.10097672e-02,  4.94017601e-02, -1.97620247e-03,\n",
       "        4.63433787e-02, -1.50929326e-02, -6.57409653e-02,  1.32598530e-03,\n",
       "        6.07045367e-03, -4.30667549e-02,  4.24196608e-02, -8.89965985e-03,\n",
       "        1.88543350e-02,  5.59672937e-02, -5.77414855e-02,  1.60586219e-02,\n",
       "       -2.69169267e-02,  2.01038849e-02,  3.15735415e-02, -9.20511410e-03,\n",
       "       -2.51679961e-02, -2.67315637e-02, -1.10815749e-01, -6.99613383e-03,\n",
       "        1.95821598e-02,  3.35026905e-02,  3.87306958e-02, -2.05537025e-02,\n",
       "        7.47765601e-02, -2.45210007e-02, -2.66909897e-02, -3.80270891e-02,\n",
       "        7.79681429e-02,  7.49008656e-02, -5.79935685e-02,  4.85020019e-02,\n",
       "        1.40849585e-02, -9.38046277e-02, -6.56680241e-02, -6.98474497e-02,\n",
       "       -6.05404424e-03,  1.46537637e-02,  1.73933376e-02, -2.55120881e-02,\n",
       "        7.74419233e-02, -6.57183230e-02, -6.30958527e-02,  5.12240417e-02,\n",
       "       -6.72984123e-02,  4.40927111e-02, -8.16238448e-02,  1.71074513e-02,\n",
       "       -2.07729600e-02, -4.00041826e-02, -5.39043592e-03,  4.68399040e-02,\n",
       "       -5.22246659e-02,  2.83277389e-02,  1.53738102e-02,  3.90994996e-02,\n",
       "        4.37702574e-02, -1.18624035e-03, -7.66584184e-03, -7.05675706e-02,\n",
       "        7.78267439e-03,  4.08752151e-02, -2.03655921e-02, -3.46521251e-02,\n",
       "       -7.12294085e-03,  1.47374779e-01,  4.71907258e-02, -2.13159099e-02,\n",
       "        3.01419734e-03,  1.45112006e-02, -3.52338813e-02,  1.76062118e-02,\n",
       "        9.74886864e-02, -6.88830465e-02, -9.97825786e-02,  2.89956015e-02,\n",
       "       -7.98321329e-03,  8.74227881e-02,  3.65227163e-02,  1.65118620e-01,\n",
       "       -1.32271219e-02,  1.72146242e-02, -3.43555259e-03, -1.54125579e-02,\n",
       "       -4.39435355e-02,  5.01314923e-02, -2.16789525e-02, -3.99872698e-02,\n",
       "        5.83672039e-02, -6.88026175e-02,  6.00133538e-02,  3.26487571e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_output = results.as_numpy('1770')\n",
    "inference_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9dbc5-6a14-4461-a5a3-60ba5e9c23bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
