{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/raul/Escritorio/extra/misis/ml_tech/mlt_project/utils/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, InputExample, models, util\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): AdapterModule(\n",
       "    (dense1): Linear(in_features=384, out_features=1024, bias=True)\n",
       "    (dense2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (output): Linear(in_features=512, out_features=384, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (3): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AdapterModule(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.3, add_residual=True):\n",
    "        super(AdapterModule, self).__init__()\n",
    "        self.dense1 = nn.Linear(in_features=input_dim, out_features=1024, bias=True)\n",
    "        self.dense2 = nn.Linear(in_features=1024, out_features=512, bias=True)\n",
    "        self.output = nn.Linear(in_features=512, out_features=output_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.add_residual = add_residual\n",
    "        if add_residual:\n",
    "            self.residual_weight = nn.Parameter(nn.init.uniform_(torch.empty(1), 0, 0.1))  # Small initialization\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = input_data.get('sentence_embedding')\n",
    "        original_x = x if self.add_residual else None\n",
    "        x = self.dropout(self.activation(self.dense1(x)))\n",
    "        x = self.dropout(self.activation(self.dense2(x)))\n",
    "        x = self.output(x)\n",
    "        if self.add_residual:\n",
    "            x += self.residual_weight * original_x\n",
    "            \n",
    "        input_data['sentence_embedding'] = x\n",
    "        \n",
    "        return input_data\n",
    "    \n",
    "    def save(self, output_path):\n",
    "        torch.save(self.state_dict(), os.path.join(output_path, 'adapter_module.pt'))\n",
    "    \n",
    "word_embedding_model = models.Transformer(\n",
    "                            model_name_or_path=\"sentence-transformers/all-MiniLM-L12-v2\", \n",
    "                            max_seq_length=128, \n",
    "                            do_lower_case=False\n",
    "                            )\n",
    "\n",
    "# Parametros default del modelo base a utilizar\n",
    "pooling_model = models.Pooling(**{'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, \n",
    "                                  'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False,\n",
    "                                  'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, \n",
    "                                  'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
    "normalize = models.Normalize()\n",
    "\n",
    "# Unica sección que tiene pesos entrenables\n",
    "for param in word_embedding_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Determinar la dimensión de entrada de acuerdo con la última capa del modelo base\n",
    "adapter = AdapterModule(384, 384).to(device)\n",
    "\n",
    "\n",
    "base_model = SentenceTransformer(modules=[word_embedding_model, pooling_model, normalize], device=device)\n",
    "\n",
    "custom_domain_model = SentenceTransformer(modules=[word_embedding_model, pooling_model, \n",
    "                                                   adapter, normalize\n",
    "                                                   ],device=device)\n",
    "\n",
    "custom_domain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_pickle('data/qa_training.pkl')\n",
    "qa_eval = pd.read_pickle('data/qa_evaluation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [\n",
    "    InputExample(texts=[qa[0], qa[1]])\n",
    "    for qa in qa\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4db9f6b0a7e4b3a84d6ed9ff8d4f344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e179f594d65b40c2902627858ea80bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1406c415d60b4e369b4f008d51ce9d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34f6efb6c0f4bb3a0b73cc7a8428488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68a3a8297a44111af5a8e18eb8686e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c490eef86a394c5da757a714cea5bfa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b889fc4917d447beae92195cb58181ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5cce3c1de14bcca428ac1a44f8ec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d274efce1994df785d2530f302623da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab9cf1406114f529bacef268be64a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47b8407442c4d36a9526b11bd5843fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ad1454318042eeb2e9da25c0b75f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c3ac8cc00b4291b3639e24127ffba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e1a6e68d8c4974964be144b45e6e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5036fd569ca4494099fb416b92cf07c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90ec90bc3564d20ade76ad7ad13f79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bfebbe61d74b6493f9cb06e617297b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b44cab8bba4dea9b56b7e1d3068851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527e3ffeb23c480bb09784dd32cd7474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff8260b798a449a9336a53580de3c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce98c28b7c29472e8bc0293973f91f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf4fb228a8d4fe9bd3f6639094ff22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = DataLoader(train_examples, shuffle=True, batch_size=64)\n",
    "train_loss = losses.MultipleNegativesSymmetricRankingLoss(custom_domain_model,\n",
    "                                                          )\n",
    "evaluator = InformationRetrievalEvaluator(qa_eval['queries'], qa_eval['corpus'], qa_eval['relevant_docs'], \n",
    "                                          name='qa_eval', main_score_function='dot_score')\n",
    "\n",
    "epochs = 250\n",
    "warmup_steps = int(len(loader) * epochs * 0.1)\n",
    "\n",
    "custom_domain_model.fit(\n",
    "    train_objectives=[(loader, train_loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='domain_adaptation_model',\n",
    "    show_progress_bar=True,\n",
    "    save_best_model=True,\n",
    "    #use_amp=True,\n",
    "    evaluator=evaluator, \n",
    "    evaluation_steps=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the base model & the custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate @ 10 (base model): 0.39\n",
      "Hit Rate @ 10 (custom model): 0.7\n"
     ]
    }
   ],
   "source": [
    "hit_rate = utils.hit_rate_at_k(qa_eval['queries'], qa_eval['corpus'], qa_eval['relevant_docs'], k=10, model=base_model)\n",
    "print(f\"Hit Rate @ 10 (base model): {round(hit_rate, 2)}\")\n",
    "\n",
    "\n",
    "hit_rate = utils.hit_rate_at_k(qa_eval['queries'], qa_eval['corpus'], qa_eval['relevant_docs'], k=10, model=custom_domain_model)\n",
    "print(f\"Hit Rate @ 10 (custom model): {round(hit_rate, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP @ 100 (base model):  0.008\n",
      "MAP @ 100 (custom model):  0.026\n"
     ]
    }
   ],
   "source": [
    "eva_base_model = evaluator(base_model, output_path='results/base_model/')\n",
    "print(\"MAP @ 100 (base model): \", round(eva_base_model, 3))\n",
    "\n",
    "eva_custom_model = evaluator(custom_domain_model, output_path='results/custom_model/')\n",
    "print(\"MAP @ 100 (custom model): \", round(eva_custom_model, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>steps</th>\n",
       "      <th>cos_sim-Accuracy@1</th>\n",
       "      <th>cos_sim-Accuracy@3</th>\n",
       "      <th>cos_sim-Accuracy@5</th>\n",
       "      <th>cos_sim-Accuracy@10</th>\n",
       "      <th>cos_sim-Precision@1</th>\n",
       "      <th>cos_sim-Recall@1</th>\n",
       "      <th>cos_sim-Precision@3</th>\n",
       "      <th>cos_sim-Recall@3</th>\n",
       "      <th>...</th>\n",
       "      <th>dot_score-Precision@3</th>\n",
       "      <th>dot_score-Recall@3</th>\n",
       "      <th>dot_score-Precision@5</th>\n",
       "      <th>dot_score-Recall@5</th>\n",
       "      <th>dot_score-Precision@10</th>\n",
       "      <th>dot_score-Recall@10</th>\n",
       "      <th>dot_score-MRR@10</th>\n",
       "      <th>dot_score-NDCG@10</th>\n",
       "      <th>dot_score-MAP@100</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.011232</td>\n",
       "      <td>0.257953</td>\n",
       "      <td>0.063791</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>base_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.389937</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.606918</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.389937</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>0.18239</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18239</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>0.121384</td>\n",
       "      <td>0.033703</td>\n",
       "      <td>0.069811</td>\n",
       "      <td>0.042558</td>\n",
       "      <td>0.485486</td>\n",
       "      <td>0.123653</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>custom_model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  steps  cos_sim-Accuracy@1  cos_sim-Accuracy@3  cos_sim-Accuracy@5  \\\n",
       "0     -1     -1            0.207547            0.283019            0.330189   \n",
       "0     -1     -1            0.389937            0.547170            0.606918   \n",
       "\n",
       "   cos_sim-Accuracy@10  cos_sim-Precision@1  cos_sim-Recall@1  \\\n",
       "0             0.386792             0.207547          0.005559   \n",
       "0             0.698113             0.389937          0.017130   \n",
       "\n",
       "   cos_sim-Precision@3  cos_sim-Recall@3  ...  dot_score-Precision@3  \\\n",
       "0              0.09434          0.007446  ...                0.09434   \n",
       "0              0.18239          0.028186  ...                0.18239   \n",
       "\n",
       "   dot_score-Recall@3  dot_score-Precision@5  dot_score-Recall@5  \\\n",
       "0            0.007446               0.066038            0.008996   \n",
       "0            0.028186               0.121384            0.033703   \n",
       "\n",
       "   dot_score-Precision@10  dot_score-Recall@10  dot_score-MRR@10  \\\n",
       "0                0.038679             0.011232          0.257953   \n",
       "0                0.069811             0.042558          0.485486   \n",
       "\n",
       "   dot_score-NDCG@10  dot_score-MAP@100          tipo  \n",
       "0           0.063791           0.007833    base_model  \n",
       "0           0.123653           0.025872  custom_model  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_eval = pd.read_csv('results/base_model/Information-Retrieval_evaluation_qa_eval_results.csv')\n",
    "base_model_eval['tipo'] = 'base_model'\n",
    "custom_model_eval = pd.read_csv('results/custom_model/Information-Retrieval_evaluation_qa_eval_results.csv')\n",
    "custom_model_eval['tipo'] = 'custom_model'\n",
    "\n",
    "pd.concat([base_model_eval, custom_model_eval])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = \"Composable Lightweight Processors\"\n",
    "author = \"Changkyu Kim\"\n",
    "author2 = \"Venturelli Guilherme Cavalheiro\"\n",
    "\n",
    "concept1 = \"shark\"\n",
    "concept2 = \"ocean\"\n",
    "concept3 = \"strawberry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producto punto entre el titulo del paper y el autor: 0.2749561667442322\n",
      "Producto punto entre dos co-autores del mismo paper: 0.6083542108535767\n",
      "Producto punto entre dos conceptos (shark y ocean): 0.7466773986816406\n",
      "Producto punto entre dos conceptos (shark y strawberry): 0.6011714339256287\n",
      "Producto punto entre el documento y un concepto (ocean): 0.22511833906173706\n"
     ]
    }
   ],
   "source": [
    "custom_paper = custom_domain_model.encode(paper)\n",
    "custom_author = custom_domain_model.encode(author)\n",
    "custom_author2 = custom_domain_model.encode(author2)\n",
    "\n",
    "custom_concept1 = custom_domain_model.encode(concept1)\n",
    "custom_concept2 = custom_domain_model.encode(concept2)\n",
    "custom_concept3 = custom_domain_model.encode(concept3)\n",
    "\n",
    "# Imprimir los resultados y explicaciones\n",
    "print(f\"Producto punto entre el titulo del paper y el autor: {np.dot(custom_paper, custom_author)}\")\n",
    "print(f\"Producto punto entre dos co-autores del mismo paper: {np.dot(custom_author, custom_author2)}\")\n",
    "print(f\"Producto punto entre dos conceptos (shark y ocean): {np.dot(custom_concept1, custom_concept2)}\")\n",
    "print(f\"Producto punto entre dos conceptos (shark y strawberry): {np.dot(custom_concept1, custom_concept3)}\")\n",
    "print(f\"Producto punto entre el documento y un concepto (ocean): {np.dot(custom_paper, custom_concept2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producto punto entre el titulo del paper y el autor: -0.07127632945775986\n",
      "Producto punto entre dos co-autores del mismo paper: 0.05467626452445984\n",
      "Producto punto entre dos conceptos (shark y ocean): 0.5232283473014832\n",
      "Producto punto entre dos conceptos (shark y strawberry): 0.23324593901634216\n",
      "Producto punto entre el documento y un concepto (ocean): -0.08226226270198822\n"
     ]
    }
   ],
   "source": [
    "base_paper = base_model.encode(paper)\n",
    "base_author = base_model.encode(author)\n",
    "base_author2 = base_model.encode(author2)\n",
    "\n",
    "base_concept1 = base_model.encode(concept1)\n",
    "base_concept2 = base_model.encode(concept2)\n",
    "base_concept3 = base_model.encode(concept3)  \n",
    "\n",
    "# Imprimir los resultados y explicaciones\n",
    "print(f\"Producto punto entre el titulo del paper y el autor: {np.dot(base_paper, base_author)}\")\n",
    "print(f\"Producto punto entre dos co-autores del mismo paper: {np.dot(base_author, base_author2)}\")\n",
    "print(f\"Producto punto entre dos conceptos (shark y ocean): {np.dot(base_concept1, base_concept2)}\")\n",
    "print(f\"Producto punto entre dos conceptos (shark y strawberry): {np.dot(base_concept1, base_concept3)}\")\n",
    "print(f\"Producto punto entre el documento y un concepto (ocean): {np.dot(base_paper, base_concept2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
